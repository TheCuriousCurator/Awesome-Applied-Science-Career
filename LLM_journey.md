- [CS480/680 Lecture 19: Attention and Transformer Networks Pascal Poupart](https://www.youtube.com/watch?v=OyFJWRnt_AY)
- [Stanford CS229 I Machine Learning I Building Large Language Models (LLMs)](https://www.youtube.com/watch?v=9vM4p9NN0Ts)
- [Coding a Transformer from scratch on PyTorch, with full explanation, training and inference.](https://www.youtube.com/watch?v=ISNdQcPhsts)
- [Let's build GPT: from scratch, in code, spelled out. Karpathy](https://www.youtube.com/watch?v=kCc8FmEb1nY)
- [Building LLMs from the Ground Up: A 3-hour Coding Workshop Sebastian Raschka](https://www.youtube.com/watch?v=quh7z1q7-uc)
- [Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE)
- [Deep Learning Deep Dive Episode #2: DALL-E and friends in image generation](https://www.youtube.com/watch?v=gMc90bqHMSM)
- [Let's reproduce GPT-2 (124M)](https://www.youtube.com/watch?v=l8pRSuU81PU)
- [BERT explained: Training, Inference, BERT vs GPT/LLamA, Fine tuning, \[CLS\] token](https://www.youtube.com/watch?v=90mGPxR2GgY)
- [LLaMA explained: KV-Cache, Rotary Positional Embedding, RMS Norm, Grouped Query Attention, SwiGLU](https://www.youtube.com/watch?v=Mn_9W1nCFLo)
- [Stanford CS25 - Transformers United](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM)
- [Stanford CS521 - AI Safety Seminar](https://www.youtube.com/playlist?list=PLoROMvodv4rNtnS3JSRRZzLWQo2dd6XNs)
- [Neural Networks: Zero to Hero - Andrej Karpathy](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)
